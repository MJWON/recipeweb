import streamlit as st
import requests
from bs4 import BeautifulSoup
import json
import urllib.parse

# --- ì„±ë³„, ë‚˜ì´ë³„ í‚¤ì›Œë“œ ë°ì´í„° (í•„ìš”ì‹œ ìˆ˜ì • ê°€ëŠ¥) ---
male_keywords = [
    "ìŠ¤í…Œì´í¬", "ì‚¼ê²¹ì‚´", "ì¹˜í‚¨", "ê°ˆë¹„", "ëˆê¹ŒìŠ¤", "í”¼ì", "í–„ë²„ê±°", "ë¼ë©´", "ì¹´ë ˆ", "ì¹˜ì¦ˆ",
    "ê°ìíƒ•", "ë–¡ë³¶ì´", "íŒŒìŠ¤íƒ€", "ì§¬ë½•", "ë§ˆë¼íƒ•", "ë¶€ëŒ€ì°Œê°œ", "ê°ì", "ê³„ë€ì°œ", "ëœì¥ì°Œê°œ", "ìˆœë‘ë¶€ì°Œê°œ",
    "ëˆë¶ˆê³ ê¸°", "ì¡±ë°œ", "ë‹­ë³¶ìŒíƒ•", "íšŒ", "ì°¸ì¹˜", "í•´ë¬¼íŒŒì „", "ë¶ˆë‹­", "ê¹€ì¹˜ì°Œê°œ", "ê¹€ë°¥", "í† ë§ˆí† íŒŒìŠ¤íƒ€"
]
female_keywords = [
    "ìƒëŸ¬ë“œ", "ì˜¤íŠ¸ë°€", "ë‹­ê°€ìŠ´ì‚´", "ê³¼ì¼", "ë‘ë¶€", "ì½©ë‚˜ë¬¼êµ­", "ì¡ê³¡ë°¥", "ë„ë¼ì§€ë¬´ì¹¨", "ê³¼ì¼ì£¼ìŠ¤", "í˜„ë¯¸ë°¥",
    "ì˜¤ë¯ˆë ›", "ì—°ì–´ìƒëŸ¬ë“œ", "ë‹­ê°€ìŠ´ì‚´ìƒëŸ¬ë“œ", "ì•„ë³´ì¹´ë„", "ì²­í¬ë¬µë¬´ì¹¨", "ì—°ë‘ë¶€", "êµ¬ìš´ì•¼ì±„", "í† ë§ˆí† ", "ë²„ì„¯ë³¶ìŒ", "ê°€ì§€êµ¬ì´",
    "ë¯¸ì—­êµ­", "ë‹¨í˜¸ë°•ì£½", "ì˜¤íŠ¸ë°€ì£½", "ë°©ìš¸í† ë§ˆí† ", "ì‹œê¸ˆì¹˜ë‚˜ë¬¼", "ê³ êµ¬ë§ˆêµ¬ì´", "ì½”ì½”ë„›ì›Œí„°", "ì•„ëª¬ë“œ", "ì•¼ì±„ìˆ˜í”„", "ë¡œì œíŒŒìŠ¤íƒ€"
]
age_keywords = {
    "20": [...],  # ìœ„ ì½”ë“œì˜ 20ëŒ€ í‚¤ì›Œë“œ
    "30": [...],  # ìœ„ ì½”ë“œì˜ 30ëŒ€ í‚¤ì›Œë“œ
    "40": [...],  # ìœ„ ì½”ë“œì˜ 40ëŒ€ í‚¤ì›Œë“œ
    "50": [...],  # ìœ„ ì½”ë“œì˜ 50ëŒ€ í‚¤ì›Œë“œ
    "60": [...],  # ìœ„ ì½”ë“œì˜ 60ëŒ€ í‚¤ì›Œë“œ
}
def get_age_keywords(age):
    try:
        age = int(age)
        decade = str((age // 10) * 10)
        return age_keywords.get(decade, [])
    except:
        return []

st.title("ë§ì¶¤í˜• ë ˆì‹œí”¼ ì¶”ì²œ ì‹œìŠ¤í…œ")

region = st.selectbox(
    "ê±°ì£¼ ì§€ì—­(ë‚˜ë¼ ì´ë¦„)ì„ ì„ íƒí•˜ì„¸ìš”",
    ["í•œêµ­", "ì¤‘êµ­", "ì¼ë³¸", "ë¯¸êµ­", "ì´íƒˆë¦¬ì•„", "í”„ë‘ìŠ¤", "ë™ë‚¨ì•„", "íƒœêµ­", "ë² íŠ¸ë‚¨", "ì¸ë„", "ê·¸ë¦¬ìŠ¤", "ë©•ì‹œì½”", "ìŠ¤í˜ì¸", "í„°í‚¤", "ëŸ¬ì‹œì•„", "ì˜êµ­", "ë…ì¼", "ë¸Œë¼ì§ˆ", "ì„¸ê³„ìš”ë¦¬"]
)
gender = st.radio("ì„±ë³„ì„ ì„ íƒí•˜ì„¸ìš”", ["ë‚¨ì„±", "ì—¬ì„±"])
age = st.text_input("ë‚˜ì´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ìˆ«ìë§Œ)", "")

st.info(f"{region} ìš”ë¦¬ë§Œ ì¶”ì²œí•©ë‹ˆë‹¤. ì¬ë£ŒëŠ” í•œêµ­ì–´ë¡œ 3ê°œ ì´ìƒ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: ê°ì, ë‹¹ê·¼, ë‹­ê³ ê¸°)")

ingredient_input = st.text_input("ì¬ë£Œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œ ë˜ëŠ” ê³µë°±ìœ¼ë¡œ êµ¬ë¶„)", "")
if ingredient_input:
    if ',' in ingredient_input:
        ingredients = [ing.strip() for ing in ingredient_input.split(',') if ing.strip()]
    else:
        ingredients = [ing.strip() for ing in ingredient_input.split() if ing.strip()]

    user_keywords = []
    if gender == "ë‚¨ì„±":
        user_keywords += [k for k in male_keywords if k not in ingredients]
    elif gender == "ì—¬ì„±":
        user_keywords += [k for k in female_keywords if k not in ingredients]
    user_keywords += [k for k in get_age_keywords(age) if k not in ingredients and k not in user_keywords]
    final_ingredients = ingredients + user_keywords[:7]

    if len(ingredients) < 3:
        st.error("â— ì¬ë£ŒëŠ” 3ê°œ ì´ìƒ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        with st.spinner("ë ˆì‹œí”¼ ê²€ìƒ‰ ì¤‘..."):
            region_map = {
                "í•œêµ­": "í•œì‹",
                "ì¤‘êµ­": "ì¤‘ì‹",
                "ì¼ë³¸": "ì¼ì‹"
            }
            category = region_map.get(region, region)
            query = "+".join(final_ingredients)
            url = f"https://www.10000recipe.com/recipe/list.html?q={category}&order=reco"
            res = requests.get(url)
            soup = BeautifulSoup(res.text, 'html.parser')
            recipes = soup.select("ul.common_sp_list_ul.ea4 li")[:20]

            results = []
            for item in recipes:
                title_tag = item.select_one(".common_sp_caption_tit")
                link_tag = item.select_one("a")
                if not title_tag or not link_tag:
                    continue
                title = title_tag.get_text(strip=True)
                link = "https://www.10000recipe.com" + link_tag["href"]
                # ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¬ë£Œ ì¶”ì¶œ
                detail = requests.get(link)
                detail_soup = BeautifulSoup(detail.text, 'html.parser')
                script_tag = detail_soup.find("script", {"type": "application/ld+json"})
                if not script_tag:
                    continue
                try:
                    json_data = json.loads(script_tag.string)
                    recipe_ingredients = json_data.get("recipeIngredient", [])
                except:
                    continue
                matched = [i for i in ingredients if any(i in ing for ing in recipe_ingredients)]
                unmatched = [i for i in recipe_ingredients if not any(ing in i for ing in ingredients)]
                match_rate = round(len(matched) / len(recipe_ingredients) * 100, 1) if recipe_ingredients else 0
                results.append({
                    "title": title,
                    "link": link,
                    "match_rate": match_rate,
                    "matched": matched,
                    "unmatched": unmatched
                })

            results = sorted(results, key=lambda x: -x['match_rate'])[:5]

        if not results:
            st.warning("ğŸ˜¢ ì…ë ¥í•œ ì¬ë£Œì™€ ì¼ì¹˜í•˜ëŠ” ë ˆì‹œí”¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.subheader(f"ğŸ½ï¸ [{region}] ë§ì¶¤í˜• ë ˆì‹œí”¼ ì¶”ì²œ ê²°ê³¼ (Top 5):")
            for i, r in enumerate(results, 1):
                st.markdown(f"**{i}. [{r['title']}]({r['link']})** ({r['match_rate']}%)")
                st.markdown(f"âœ… **ì¼ì¹˜í•œ ì¬ë£Œ:** {', '.join(r['matched']) if r['matched'] else 'ì—†ìŒ'}")
                st.markdown(f"âŒ **ë¶€ì¡±í•œ ì¬ë£Œ:** {', '.join(r['unmatched']) if r['unmatched'] else 'ì—†ìŒ'}")
                if r['unmatched']:
                    st.markdown("ğŸ›’ **ì¥ë°”êµ¬ë‹ˆ**")
                    for item in r['unmatched']:
                        encoded = urllib.parse.quote_plus(item)
                        link = f"https://www.coupang.com/np/search?component=&q={encoded}"
                        st.markdown(f"- [{item}]({link})")
                st.write("")

# age_keywords ê°’ ì±„ìš°ê¸° ì˜ˆì‹œ (ìƒëµëœ ë¶€ë¶„ì„ ìœ„ ì½”ë“œì—ì„œ ë³µì‚¬í•´ì„œ ë„£ìœ¼ì„¸ìš”)
